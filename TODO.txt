major TODOs
 * when feeding: overwrite existing! use idField
 * feeding via HTTP
 * range queries
 * better scoring (with tf = min(4,tf))
 * is there really no common way to improve the speed of iterating over an hash ala Java:
   for(var key, value in hash.entries) {  }

support fq param

when querying solr index: convert <date>...</date> to Date instance
    parse date when feeding convert to long/Date? /SECOND /MINUTE !?
FATAL ERROR: CALL_AND_RETRY_2 Allocation failed - process out of memory
    Sun Oct 31 2010 22:22:04 GMT+0100 (CET)| {"start":"30000","q":"","wt":"json","rows":"1000"} returned 1000 documents. feeding time:0.157 total:4718030 RAM:351.11147689819336 MB
    Sun Oct 31 2010 22:23:02 GMT+0100 (CET)| {"start":"31000","q":"","wt":"json","rows":"1000"} returned 1000 documents. feeding time:1.751 total:4718030 RAM:372.17225646972656 MB
    => 5-6 KB for 1 doc !?
    call gc explicitely! increase available RAM!?

measure RAM usage + qtime when load testing
regular refresh via F5 -> only first result differs
range query date:[NOW-8HOUR TO *]
    create a filter cache. keys als "date:[mySpecialFilter]" values ala DocBitSet (docs that fullfill the query)
search in AND-results via doc.field.indexOf("x y z") when querying "x y z" (query with "" !)
npm install jsii
js twitter clients
    http://github.com/masylum/twitter-js
    http://github.com/jdub/node-twitter

SolrJ
* solrj does not have a JSONResponseParser yet: https://issues.apache.org/jira/browse/SOLR-402
  but XMLResponseParser can be used !